{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "AeANrUEqQWZI"
      ],
      "authorship_tag": "ABX9TyPbu5/rm7yUdibh/FnIMooC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eleanorjolliffe/Capstone-2025/blob/main/Capstone_Analysis_Part_2_Climate_misinformation_detection_using_Semantic_Similarity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Installing the necessary packages"
      ],
      "metadata": {
        "id": "PcZjUK6_Pe2U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3aX1-C0O0ZW",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install -U sentence-transformers\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import textwrap\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Testing 4 SBERT models to evaluate their ability to detect climate misinformation"
      ],
      "metadata": {
        "id": "4v24FgakO8Ts"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Climate misinformation taxonomy and test statements"
      ],
      "metadata": {
        "id": "giNXdVTePUsz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "misinformation_examples = pd.read_csv('/content/Climate misinformation examples.csv')"
      ],
      "metadata": {
        "id": "8wy2qfB0XaY7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#my test statements - 5 are climate misinfo, 3 are climate related and 2 are random\n",
        "statements = [\n",
        "    \"I don't believe climate change is real - it is no warmer than it has been before and the ice isn't melting. It's honestly cold.\",\n",
        "    \"NASA admits climate change occurs because of changes in Earth's solar orbit, not because of SUVS and fossil fuels\",\n",
        "    \"Climate change isn’t actually a danger to our health.\",\n",
        "    \"Electric cars are more environmentally devastating than petrol cars - they are charged on the nuclear power grid, they are encouraging lithium mining and their batteries degenerate.\",\n",
        "    \"Leading meteorologist denounces wildfires as a fake climate con. They call for the arrest and imprisonment of Greta Thunberg and Sadiq Khan.\",\n",
        "    \"This is absurd moral relativism. Did you not see Rhodes this year? Are you really a climate change denier in this day and age?\",\n",
        "    \"Realistically, it's about bringing down the harmful particulates emitted by older diesel engines.\",\n",
        "    \"But but... I work hard to afford a Range Rover so I can drive my kids to school.\",\n",
        "    \"Poorer Londoners are significantly less likely to own a car and they're also much more likely to be worst affected by air pollution.\",\n",
        "    \"Maybe in 70 years, they’ll admit the Covid jab was a dangerous Experiment\"\n",
        "]"
      ],
      "metadata": {
        "id": "qNBwr7_5YJY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function for semantic similarity testing & heatmap plotting"
      ],
      "metadata": {
        "id": "LT3xKZgfQAJb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The function below has three inputs, the sentence transformer model, climate misinformation examples and test statements. It first applies the model to calculate dense vectors for each climate misinformation statement, and then it calculates the dense vectors of each test statement. Next, using cosine similarity, the distance between each test statement and each climate misinformation statement is calculated. Next, I iterated through the results to find the highest score for each statement and the climate misinformation example it was most highly matched to, saving these in an empty list created earlier."
      ],
      "metadata": {
        "id": "q5Ez3ya8ag2K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def misinformation_testing(model, misinformation_examples_list, test_statements):\n",
        "    misinformation_embeddings = model.encode(misinformation_examples_list, convert_to_tensor=True)\n",
        "    test_embeddings = model.encode(test_statements, convert_to_tensor=True)\n",
        "\n",
        "    similarity_matrix = util.cos_sim(test_embeddings, misinformation_embeddings)\n",
        "\n",
        "    results = []\n",
        "    for i, sims in enumerate(similarity_matrix):\n",
        "        best_idx = sims.argmax().item()\n",
        "        best_score = sims[best_idx].item()\n",
        "        best_example = misinformation_examples_list[best_idx]\n",
        "        results.append({\n",
        "            \"Test Statement\": test_statements[i],\n",
        "            \"Most Similar Example\": best_example,\n",
        "            \"Similarity Score\": best_score\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "misinformation_examples_list = misinformation_examples['Climate misinformation example'].tolist()"
      ],
      "metadata": {
        "id": "UGdRmXLTXR_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using plotly, the function below visualises the semantic similarity scores calculated above. It first makes a copy of the dataframe which is used to wrap the statements making the graph more readable as statements are over multiple lines. Other features include a horizontal orientation, a colour which reflects the strength of the similarity score and hover data which includes the most similar example.\n"
      ],
      "metadata": {
        "id": "Xia7kKfmdufn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_misinformation_similarity_plotly(df_results, title=\"Climate Misinformation Similarity\", wrap_width=40):\n",
        "    df = df_results.copy()\n",
        "    df[\"Wrapped Statement\"] = df[\"Test Statement\"].apply(lambda x: \"<br>\".join(textwrap.wrap(x, width=wrap_width)))\n",
        "\n",
        "    fig = px.bar(\n",
        "        df,\n",
        "        x=\"Similarity Score\",\n",
        "        y=\"Wrapped Statement\",\n",
        "        orientation=\"h\",\n",
        "        title=title,\n",
        "        color=\"Similarity Score\",\n",
        "        color_continuous_scale=px.colors.sequential.Blues,\n",
        "        hover_data  =[\"Most Similar Example\"],\n",
        "        labels = {\"Similarity Score\": \"Semantic Similarity Score\"}\n",
        "    )\n",
        "\n",
        "    fig.update_layout(\n",
        "        xaxis_title=\"Semantic Similarity Score\",\n",
        "        yaxis_title=\"Test Statement\",\n",
        "        yaxis=dict(autorange=\"reversed\"),\n",
        "        title_x=0.5,\n",
        "        font=dict(size=6),\n",
        "    )\n",
        "\n",
        "    fig.show()\n"
      ],
      "metadata": {
        "id": "u2WdYP9IoFo1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### all-MiniLM-L6-v2"
      ],
      "metadata": {
        "id": "AeANrUEqQWZI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#loading the all mini lm sentence transformer\n",
        "model_all_Mini = SentenceTransformer('all-MiniLM-L6-v2')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "u-sKrgW3QbvL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#applying the misinformation testing function to calculate semantic similarity between climate misinfo examples and test statements\n",
        "df_MiniLM_results = misinformation_testing(model_all_Mini, misinformation_examples_list, statements)"
      ],
      "metadata": {
        "id": "5PxZ0aGjQSvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_misinformation_similarity_plotly(df_MiniLM_results, title ='Mini LM CLimate misinformation test')"
      ],
      "metadata": {
        "id": "kw5SWN2FZBjm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### paraphrase-MiniLM-L12-v2"
      ],
      "metadata": {
        "id": "crqx8Wd_Rh-S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#loading the paraphrase mini lm sentence transformer\n",
        "model_para = SentenceTransformer('paraphrase-MiniLM-L12-v2')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "3KyLsNh5Rmys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#applying the misinformation testing function to calculate semantic similarity between climate misinfo examples and test statements\n",
        "df_para_MiniLM_results = misinformation_testing(model_para, misinformation_examples_list, statements)"
      ],
      "metadata": {
        "id": "X0OYDF1odAvX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_misinformation_similarity_plotly(df_para_MiniLM_results, title ='Paraphrase Mini LM Climate Misinformation test')"
      ],
      "metadata": {
        "id": "CljFNM0toKWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###paraphrase-mpnet-base-v2"
      ],
      "metadata": {
        "id": "3fvzXjVXSHHJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#loading the paraphrase mpnet sentence transformer\n",
        "model_mpnet = SentenceTransformer('paraphrase-mpnet-base-v2')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "jUoYqq0fSMcH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#applying the misinformation testing function to calculate semantic similarity between climate misinfo examples and test statements\n",
        "df_para_mpnet_results = misinformation_testing(model_mpnet, misinformation_examples_list, statements)"
      ],
      "metadata": {
        "id": "PBfqayQNSQYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_misinformation_similarity_plotly(df_para_mpnet_results, title=\"Paraphrase mpnet base Climate Misinformation test\")"
      ],
      "metadata": {
        "id": "yhiUDLHtSW_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###all-mpnet-base-v2"
      ],
      "metadata": {
        "id": "0FEOdtG9SiPg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#loading the all mpnet sentence transformer\n",
        "model_all_mpnet = SentenceTransformer('all-mpnet-base-v2')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "3Pu_b0BRSlUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#applying the misinformation testing function to calculate semantic similarity between climate misinfo examples and test statements\n",
        "df_all_mpnet_results = misinformation_testing(model_all_mpnet, misinformation_examples_list, statements)"
      ],
      "metadata": {
        "id": "CVlIVggMSn8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_misinformation_similarity_plotly(df_all_mpnet_results, title=\"All mpnet base Climate Misinformation test\")"
      ],
      "metadata": {
        "id": "EhrlJQdkSwC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Applying chosen model, all mini lm, to random batch samples of Reddit & Telegram data"
      ],
      "metadata": {
        "id": "YZujeRi9S1SV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following section applies the chosen sentence transformer, all mini lm, to random 50-message-long batches of Reddit and Telegram data to flag any issues early. E.g., persistent false positives or negatives."
      ],
      "metadata": {
        "id": "M7vdbTlDi3wl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#applying all mini lm to calculate the vectors on the climate misinformation example\n",
        "all_Mini_example_embeddings = model_all_Mini.encode(misinformation_examples['Climate misinformation example'], convert_to_tensor=True)"
      ],
      "metadata": {
        "id": "rpAlWuLATqfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "telegram = pd.read_csv('/content/final_clean_telegram_ulez.csv')\n",
        "reddit = pd.read_csv('/content/final_clean_reddit_ulez.csv')"
      ],
      "metadata": {
        "id": "zjwM-vmgUl06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code below was applied to random samples of 50 messages from anywhere within my datasets (ten are shown here as an example). By examining the most similar messages for random sentences, I was able to identify why some false negatives and positives were occurring and adapt my method accordingly. Notably, false positives occurred when general climate discourse was assigned high scores. To address this, I created examples of neutral climate discourse and added them to the dataset to detect if a message actually scored higher than neutral climate discourse. False negatives also occurred as climate misinformation on Telegram often linked the loss of freedom to climate policy, something which was not yet reflected in my examples. To deal with this, I added more examples reflecting that sentiment. This process also helped confirm that using average similarity provided little help in my analysis, as the range of climate misinformation means that even if something is considered climate misinformation, it is not similar to a significant portion of climate misinformation examples. So, the average essentially flattens out helpful information.\n",
        "\n",
        "As for the code, a for loop is used to look through a specified range within the dataset, computing the cosine similarity between these random sentences and the climate misinformation example dataset. The average similarity, top similarity and top sentence it was matched to were saved and printed for close inspection."
      ],
      "metadata": {
        "id": "ZoDSvGtilg-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for statement in telegram['clean_message'][20000:20010]:\n",
        "    statement_embedding = model_all_Mini.encode(statement, convert_to_tensor=True)\n",
        "    cosine_scores = util.cos_sim(statement_embedding, all_Mini_example_embeddings)[0]\n",
        "\n",
        "    avg_similarity = cosine_scores.mean().item()\n",
        "    max_similarity = cosine_scores.max().item()\n",
        "    max_idx = cosine_scores.argmax().item()\n",
        "    best_match = misinformation_examples['Climate misinformation example'][max_idx]\n",
        "\n",
        "    print(f\"\\nStatement: {statement}\")\n",
        "    print(f\"Average Similarity: {avg_similarity:.4f}\")\n",
        "    print(f\"Highest Similarity: {max_similarity:.4f}\")\n",
        "    print(f\"Best Matching Taxonomy Sentence: '{best_match}'\")"
      ],
      "metadata": {
        "id": "hk3YYn_zUVxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Applying the iterated taxonomy to the entire dataset"
      ],
      "metadata": {
        "id": "XSr0a3BaWLMZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "climate_misinfo_neutral_examples = pd.read_csv('/content/Final climate misinformation : neutral examples.csv')\n",
        "telegram = pd.read_csv('/content/final_clean_telegram_ulez.csv')\n",
        "reddit = pd.read_csv('/content/final_clean_reddit_ulez.csv')"
      ],
      "metadata": {
        "id": "MV3TP_gOKgzB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#applying all mini lm to calculate the vectors on the climate misinformation and neutral discourse examples\n",
        "all_example_embeddings = model_all_Mini.encode(climate_misinfo_neutral_examples['Climate misinformation/ neutral example'], convert_to_tensor=True)"
      ],
      "metadata": {
        "id": "vHc8GJdgKs1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The function below applies the sentence transformer model, all mini LM, to calculate the semantic similarity between every message in the DataFrame and the predefined climate misinformation and neutral statements. It first converts the DataFrame inputs into a list of strings and then calculates dense vectors for each message. Next, lists are initialised to store the results, including the highest similarity score, the most similar example message and the predicted class, which is either neutral or misinfo. Next, the cosine similarity between every message and every climate misinfo / neutral discourse example is calculated, and results are saved in the initialised lists. Finally, results are stored in a DataFrame."
      ],
      "metadata": {
        "id": "rI-7-JBGoxnU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_similarity(df, text_column):\n",
        "    message_embeddings = model_all_Mini.encode(df[text_column].tolist(), convert_to_tensor=True)\n",
        "\n",
        "    highest_semantic_similarity_score = []\n",
        "    most_similar_phrases = []\n",
        "    predicted_class = []\n",
        "\n",
        "    for i, message_embedding in enumerate(message_embeddings):\n",
        "        cosine_scores = util.cos_sim(message_embedding, all_example_embeddings)[0]\n",
        "\n",
        "        best_idx = int(np.argmax(cosine_scores))\n",
        "        best_score = float(cosine_scores[best_idx])\n",
        "        best_phrase = climate_misinfo_neutral_examples['Climate misinformation/ neutral example'][best_idx]\n",
        "        best_label = climate_misinfo_neutral_examples['Climate misinformation / neutral'][best_idx]\n",
        "\n",
        "        highest_semantic_similarity_score.append(best_score)\n",
        "        most_similar_phrases.append(best_phrase)\n",
        "        predicted_class.append(best_label)\n",
        "\n",
        "    df['Highest semantic similarity score'] = highest_semantic_similarity_score\n",
        "    df['Most similar phrase'] = most_similar_phrases\n",
        "    df['Misinfo / Neutral'] = predicted_class\n",
        "\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "8g57rkhlKbeL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#applying the function to all the telegram data\n",
        "telegram_semantic_similarity = compute_similarity(telegram, text_column='clean_message')"
      ],
      "metadata": {
        "id": "BOF2Lp1hMoXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#applying the function to all the telegram data\n",
        "reddit_semantic_similarity = compute_similarity(reddit, text_column='clean_message')"
      ],
      "metadata": {
        "id": "zuhtkn8qlbEi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#labelling everything with a similarity score of under 0.55 neutral\n",
        "reddit_semantic_similarity.loc[reddit_semantic_similarity['Highest semantic similarity score'] < 0.55, 'Misinfo / Neutral'] = 'neutral'\n",
        "telegram_semantic_similarity.loc[telegram_semantic_similarity['Highest semantic similarity score'] < 0.55, 'Misinfo / Neutral'] = 'neutral'"
      ],
      "metadata": {
        "id": "2-RoPTvare8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "telegram_semantic_similarity.to_csv('telegram_sem_similarity.csv', index=False)\n",
        "files.download('telegram_sem_similarity.csv')\n",
        "\n",
        "reddit_semantic_similarity.to_csv('reddit_sem_similarity.csv', index=False)\n",
        "files.download('reddit_sem_similarity.csv')"
      ],
      "metadata": {
        "id": "AgLaw1hsExQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing accuracy using F1 score"
      ],
      "metadata": {
        "id": "aqsNmIw2RA_W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The function first sorts the results by the highest semantic similarity score and then creates a new dataframe with the top 50 messages from each quartile."
      ],
      "metadata": {
        "id": "iHWCRXcjsZHh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def top_n_from_quartiles(df, sort_by, n=50):\n",
        "    df_sorted = df.sort_values(by=sort_by,  ascending=False).reset_index(drop=True)\n",
        "\n",
        "    rows_per_quartile = len(df_sorted) // 4\n",
        "\n",
        "    q1 = df_sorted.iloc[0:rows_per_quartile].head(n)\n",
        "    q2 = df_sorted.iloc[rows_per_quartile:2*rows_per_quartile].head(n)\n",
        "    q3 = df_sorted.iloc[2*rows_per_quartile:3*rows_per_quartile].head(n)\n",
        "    q4 = df_sorted.iloc[3*rows_per_quartile:].head(n)\n",
        "\n",
        "    return pd.concat([q1, q2, q3, q4], ignore_index=True)"
      ],
      "metadata": {
        "id": "5ItePFcIRDhP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating a new dataframe with the top 50 messages from every quartile\n",
        "reddit_top50_pq = top_n_from_quartiles(reddit_semantic_similarity, sort_by='Highest semantic similarity score', n=50)\n",
        "telegram_top50_pq = top_n_from_quartiles(telegram_semantic_similarity, sort_by='Highest semantic similarity score', n=50)"
      ],
      "metadata": {
        "id": "94a6T7XVaM1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating a new column which assigns messages labelled misinfo 1 and those labelled neutral 0\n",
        "reddit_top50_pq['Binary number'] = reddit_top50_pq['Misinfo / Neutral'].apply(lambda x: 1 if x == 'misinfo' else 0)\n",
        "telegram_top50_pq['Binary number'] = telegram_top50_pq['Misinfo / Neutral'].apply(lambda x: 1 if x == 'misinfo' else 0)"
      ],
      "metadata": {
        "id": "8Jlgyusns14d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reddit_top50_pq.to_csv('Reddit top 50 per quartile.csv', index=False)\n",
        "files.download('Reddit top 50 per quartile.csv')\n",
        "\n",
        "telegram_top50_pq.to_csv('Telegram top 50 per quartile.csv', index=False)\n",
        "files.download('Telegram top 50 per quartile.csv')"
      ],
      "metadata": {
        "id": "kP1NQczSa3zI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After downloading the CSV, I manually reviewed every message to verify whether it was assigned the correct value. I recorded the correct value in a new column 'Real number'. I then concatenated the top 50 messages from Reddit and Telegram, per quartile, with my manually added 'Real number' column. This ensured only one classification report was produced.\n"
      ],
      "metadata": {
        "id": "rWjsXJH4s7Ey"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r_labelled = pd.read_csv('/content/Reddit manually labelled top 50 per quartile.csv')\n",
        "t_labelled = pd.read_csv('/content/Telegram manually labelled top 50 per quartile.csv')\n",
        "combined_t_r_labelled = pd.concat([r_labelled, t_labelled], ignore_index=True)"
      ],
      "metadata": {
        "id": "wPfzobCd6C9-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below, I evaluate the performance of the climate misinformation detection model by first importing the necessary function. Next, I assign y_true the column I manually generated, ‘Real value’, which has the correct labels for every message: 1 for misinformation and 0 for neutral. I also assign y_pred the model-generated results, ‘Binary number, again 1 for misinformation and 0 for neutral. Finally, I generate a classification report which calculates and prints the following metrics for each class (misinformation and neutral): precision, recall, F1-score, and support."
      ],
      "metadata": {
        "id": "tzGJJlo40W3m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "y_true = combined_t_r_labelled['Real value']\n",
        "y_pred = combined_t_r_labelled['Binary number']\n",
        "print(classification_report(y_true, y_pred))"
      ],
      "metadata": {
        "id": "jTB4w9I07cUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparative analysis"
      ],
      "metadata": {
        "id": "Ok5sRXeYO_Ji"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### How prevalent is climate misinformation across the two platforms"
      ],
      "metadata": {
        "id": "wzbDOAd8PMCb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reddit_ss = pd.read_csv('/content/FINAL reddit_sem_similarity (2).csv')\n",
        "telegram_ss = pd.read_csv('/content/FINAL telegram_sem_similarity (2).csv')"
      ],
      "metadata": {
        "id": "7BcmI7amRoJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculating the percentage of discourse climate misinformatoin accounts for within the two platforms\n",
        "misinfo_counts_r = reddit_ss['Misinfo / Neutral'].value_counts()\n",
        "misinfo_count_r = misinfo_counts_r.get('misinfo', 0)\n",
        "percent_misinfo_r = (misinfo_count_r / len(reddit_ss)) * 100\n",
        "\n",
        "misinfo_counts_t = telegram_ss['Misinfo / Neutral'].value_counts()\n",
        "misinfo_count_t = misinfo_counts_t.get('misinfo', 0)\n",
        "percent_misinfo_t = (misinfo_count_t / len(telegram_ss)) * 100"
      ],
      "metadata": {
        "id": "T136DxvOPSOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "platform_misinfo = pd.DataFrame({'Platform': ['Reddit', 'Telegram'], '% Climate misinfo': [percent_misinfo_r, percent_misinfo_t]})\n",
        "fig = px.bar(platform_misinfo, x='Platform', y='% Climate misinfo', title = '% of climate misinformation within the discourse across platforms')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "mjQGllEzQNa1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Who spreads misinformation and how often?"
      ],
      "metadata": {
        "id": "wEbr4FBuZeYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reddit_spreaders = reddit_ss[reddit_ss['Misinfo / Neutral'] == 'misinfo']['hashed_user'].value_counts()\n",
        "telegram_spreaders = telegram_ss[telegram_ss['Misinfo / Neutral'] == 'misinfo']['hashed_user'].value_counts()"
      ],
      "metadata": {
        "id": "dRyzre1ZR2fI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code below visualises how much climate misinformation the top 20 spreaders spread (on Reddit and Telegram). The code first sorts the spreaders’ dataframes in descending order and then selects the top twenty using head(). This is saved in a new DataFrame which is then used for visualisation using plotly.\n"
      ],
      "metadata": {
        "id": "3qjbQqoc3mxw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_reddit_spreaders = reddit_spreaders.sort_values(ascending=False).head(20)\n",
        "reddit_df = pd.DataFrame({\n",
        "    'Count': top_reddit_spreaders.values\n",
        "})\n",
        "\n",
        "fig_reddit = px.bar(reddit_df,\n",
        "                    y='Count',\n",
        "                    title='Top 20 Users Spreading Climate Misinfo on Reddit',\n",
        "                    labels={'Count': 'No. of Climate Misinfo Messages'},\n",
        "                    color_discrete_sequence=['darkblue'])\n",
        "fig_reddit.show()\n",
        "\n",
        "top_telegram_spreaders = telegram_spreaders.sort_values(ascending=False).head(20)\n",
        "telegram_df = pd.DataFrame({\n",
        "    'Count': top_telegram_spreaders.values\n",
        "})\n",
        "\n",
        "fig_telegram = px.bar(telegram_df,\n",
        "                      y='Count',\n",
        "                      title='Top 20 Users Spreading Climate Misinfo on Telegram',\n",
        "                      labels={'Count': 'No. of Climate Misinfo Messages'},\n",
        "                      color_discrete_sequence=['darkblue'])\n",
        "fig_telegram.show()"
      ],
      "metadata": {
        "id": "HOs5QXxPiVwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#this code uses various techniques to calculate some basic statistics, which illustrate the spread of climate misinformation\n",
        "misinfo_reddit = reddit_ss[reddit_ss['Misinfo / Neutral'] == 'misinfo']\n",
        "misinfo_telegram = telegram_ss[telegram_ss['Misinfo / Neutral'] == 'misinfo']\n",
        "\n",
        "top_reddit_spreader_count = reddit_spreaders.iloc[0]\n",
        "top_telegram_spreader_count = telegram_spreaders.iloc[0:3]\n",
        "\n",
        "total_reddit_misinfo_count = len(misinfo_reddit)\n",
        "total_telegram_misinfo_count = len(misinfo_telegram)\n",
        "\n",
        "percentage_misinfo_top_reddit_spreader = (top_reddit_spreader_count / total_reddit_misinfo_count) * 100\n",
        "percentage_misinfo_top_telegram_spreaders = (top_telegram_spreader_count / total_telegram_misinfo_count) * 100\n",
        "\n",
        "unique_misinfo_users_r = misinfo_reddit['hashed_user'].nunique()\n",
        "unique_misinfo_users_t = misinfo_telegram['hashed_user'].nunique()\n",
        "\n",
        "unique_ulez_users_r = reddit_ss['hashed_user'].nunique()\n",
        "unique_ulez_users_t = telegram_ss['hashed_user'].nunique()\n",
        "\n",
        "\n",
        "print(f\"The single top climate misinformation spreader on Reddit contributes to {percentage_misinfo_top_reddit_spreader:.2f}% \"\n",
        "      f\"of climate misinformation on the platform, out of {unique_misinfo_users_r} users who spread climate misinformation \"\n",
        "      f\"and {unique_ulez_users_r} users who posted about ULEZ overall.\")\n",
        "\n",
        "print(f\"The 6 top climate misinformation spreaders on Telegram contributes to {percentage_misinfo_top_telegram_spreaders.sum():.2f}% \"\n",
        "      f\"of climate misinformation on the platform, out of {unique_misinfo_users_t} users who spread climate misinformation \"\n",
        "      f\"and {unique_ulez_users_t} users who posted about ULEZ overall.\")"
      ],
      "metadata": {
        "id": "iE-NFopsM98z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###What subreddits / telegram channels are misinfo hotbeds?"
      ],
      "metadata": {
        "id": "UcszWdYEjoV2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating the percentage of climate misinformation on each subreddit\n",
        "subreddit_spreaders = misinfo_reddit['subreddit'].value_counts()\n",
        "subreddit_freq = reddit_ss['subreddit'].value_counts()\n",
        "\n",
        "common_subreddits = subreddit_spreaders.index.intersection(subreddit_freq.index)\n",
        "subreddit_misinfo_pct = (subreddit_spreaders[common_subreddits] / subreddit_freq[common_subreddits]) * 100\n",
        "subreddit_misinfo_pct = subreddit_misinfo_pct.sort_values(ascending=False)"
      ],
      "metadata": {
        "id": "cuPEn6a2jr6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#using plotly to visualise the results\n",
        "df_subreddit_misinfo = subreddit_misinfo_pct.reset_index()\n",
        "df_subreddit_misinfo.columns = ['Subreddit', 'Percentage of Climate Misinfo Posts']\n",
        "\n",
        "fig = px.bar(df_subreddit_misinfo,\n",
        "             x='Subreddit', y='Percentage of Climate Misinfo Posts',\n",
        "             title='Percentage of Climate Misinfo Posts Across Subreddits',\n",
        "             labels={'Percentage of Climate Misinfo Posts': '% of Posts'},\n",
        "             color_discrete_sequence=['indianred'])\n",
        "\n",
        "fig.update_layout(xaxis_tickangle=-45)\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "ptFgu5D4kplW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating the percentage of climate misinformation on each telegram channel\n",
        "telegram_c_spreaders = misinfo_telegram['group_name'].value_counts()\n",
        "t_c_freq = telegram_ss['group_name'].value_counts()\n",
        "\n",
        "common_channels = telegram_c_spreaders.index.intersection(t_c_freq.index)\n",
        "channel_misinfo_pct = (telegram_c_spreaders[common_channels] / t_c_freq[common_channels]) * 100\n",
        "channel_misinfo_pct = channel_misinfo_pct.sort_values(ascending=False)"
      ],
      "metadata": {
        "id": "r6S3UmzSlZ6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#using plotly to visualise the results (largely the same as above, aside from the fact that I create a function which splits the text roughly\n",
        "#into thirds due to the lost channel names, which ensures readability on the graph)\n",
        "\n",
        "df_channel_misinfo = channel_misinfo_pct.reset_index()\n",
        "df_channel_misinfo.columns = ['Channel', 'Percentage of Climate Misinfo Posts']\n",
        "def split_in_half(text):\n",
        "    words = text.split()\n",
        "    half = math.ceil(len(words) / 3)\n",
        "    return ' '.join(words[:half]) + '<br>' + ' '.join(words[half:])\n",
        "\n",
        "df_channel_misinfo['Channel_wrapped'] = df_channel_misinfo['Channel'].apply(split_in_half)\n",
        "\n",
        "fig = px.bar(df_channel_misinfo,\n",
        "             x='Channel_wrapped', y='Percentage of Climate Misinfo Posts',\n",
        "             title='Percentage of Climate Misinfo Posts Across Telegram Channels',\n",
        "             labels={'Percentage of Climate Misinfo Posts': '% of Posts'},\n",
        "             color_discrete_sequence=['indianred'])\n",
        "\n",
        "fig.update_layout(\n",
        "    xaxis_tickfont=dict(size=7),\n",
        "    title_font_size=18,\n",
        "    yaxis_title='% of Posts',\n",
        "    xaxis_title='Channel',\n",
        ")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "c9dfpxAwlxtR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}